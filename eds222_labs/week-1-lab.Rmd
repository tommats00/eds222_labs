---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Section 0: Getting set up

Load all the packages you need, plus the `_common.R` source file.

```{r, include=TRUE}

# You probably already have these packages installed, so let's just load them
library(tidyverse)
library(readr)
library(gt)
library(openintro)

# Where is the root directory where all your labs live? If you want to set up as an .RProj, go for it. 
#rootdir <- "/C/MEDS/EDS_222/eds222_labs_discussions/"

# This runs the script _common.R, which loads all the packages we'll need for today and does some extra stuff we won't really use, at least for now.
source(here::here("eds222_labs","_common.R"))
#source(file.path(rootdir,"eds222_labs", "_common.R"))

# For labs, we want to see all our code
knitr::opts_chunk$set(echo = TRUE)
```

# Section 1: Summarize and describe **categorical** variables

We spent most of class on Tuesday discussing how to summarize _numerical_ variables. In contrast, _categorical_ variables can only take on one of a fixed number of values, so it doesn't make sense to do things like take averages (e.g., What is the "average" state in the US? What is the "average" tree species? These are not sensible questions!). Here, we will learn some helpful ways to summarize and display categorical variables.^[Note: this section follows [IMS Chapter 4](https://openintro-ims.netlify.app/explore-categorical.html) very closely! Lots more fun examples in their text if you want more practice.] 

First, let's take a look at some data with categorical variables in it. Load the `loans_full_schema` data provided in the `openintro` package. Description from IMS:

> "This data set represents thousands of loans made through the Lending Club platform, which is a platform that allows individuals to lend to other individuals. Of course, not all loans are created equal. Someone who is a essentially a sure bet to pay back a loan will have an easier time getting a loan with a low interest rate than someone who appears to be riskier. And for people who are very risky? They may not even get a loan offer, or they may not have accepted the loan offer due to a high interest rate. It is important to keep that last part in mind, since this data set only represents loans actually made, i.e. do not mistake this data for loan applications!"

We will focus on two variables:

- `homeownership`, which indicates whether the loan applicant owns, has a mortgage on, or rents their home.

- `application_type`, which indicates whether the applicant is applying as an individual, or joint with a partner. 

## Take a look at your data

Let's investigate these variable types as stored in `R`. Do they make sense to you?^[Are these "ordinal" or "nominal" categorical variables?] What about the variable `interest_rate`?

```{r}
glimpse(loans_full_schema)
```

Create a dataframe called `loans` that cleans up the full dataset `loans_full_schema` to a) make the `homeownership` variable lower case (all caps is intense...), and b) reorder the "levels" of each variable into a sensible order.^[Note: reordering levels with `fct_relevel()` is helpful if your variable has a natural ordering to it, as all visuals will follow the order of the factor levels.] 

```{r}
loans <- loans_full_schema %>% 
  mutate(homeownership = stringr::str_to_lower(homeownership)) %>% 
  mutate(homeownership = forcats::fct_relevel(homeownership, c("rent", "mortgage", "own")))
```

## Bar plots

A bar plot is a common way to display a single categorical variable. The left panel below shows a bar plot for the homeownership variable. In the right panel, the counts are converted into proportions, showing the proportion of observations that are in each level.

> Question: When might you prefer the left version of the bar plot? When might you prefer the right? 

```{r loan-homeownership-bar-plot, fig.cap = "Two bar plots: the left panel shows the counts and the right panel shows the proportions of values of the homeownership variable.", fig.asp=0.5, fig.fullwidth=TRUE}

loans_sum <- loans %>% 
  group_by(homeownership) %>% 
  count()


# Bar plot showing count of loans in each homeownership category

ggplot(loans_sum) +
  geom_col(aes(x = homeownership, y = n),    ## This bar plot shows that fct_relevel worked b/c rent, 
           fill = "slateblue4") +             ## mortgagae, and own are ordered respectively
  theme_bw()



# Bar plot showing proportion of loans in each homeownership category

ggplot(loans_sum) +
  geom_col(aes(x = homeownership, y = n/sum(n)),
           fill = "slateblue4") +
  theme_bw()
```

## Contingency tables

We often care about how two categorical variables interact with one another. For example, are homeowners more likely to apply for a loan with a partner than are renters? A **contingency table** summarizes the distribution of our data across the two categories jointly.

Each value in the table represents the number of times a particular combination of variable outcomes occurred.

For example, the value 3496 corresponds to the number of loans in the dataset where the borrower rents their home and the application type was by an individual. Row and column totals are also included. The row totals provide the total counts across each row and the column totals down each column. 

```{r loan-home-app-type-totals, fig.fullwidth=TRUE}
loans_table <- loans %>% 
  group_by(application_type, homeownership) %>% 
  tally() %>% 
  spread(key = homeownership, value = n) %>% 
  ungroup() %>% 
  group_by(application_type) %>% 
  mutate(total = sum(c(mortgage, own, rent))) %>% 
  ungroup() %>% 
  bind_rows(summarise_all(., list(~ if(is.numeric(.)) sum(., na.rm = TRUE) else "Total")))  

loans_table %>% 
  gt(rowname_col = "application_type") %>% 
  tab_spanner(columns = 2:4,
              label = "homeownership") %>% 
  tab_stubhead(label = "application type") %>% 
  tab_header(title = "Contingency table for application type and homeownership") 

## tally() automatically sums up the values that we group_by
```

## Bar plots with two variables

We can display the distributions of two categorical variables on a bar plot at the same time. These plots are generally useful for visualizing the relationship between two categorical variables.

For example, here we create three bar plots that visualize the relationship between `homeownership` and `application_type` variables.

- First, we make a **stacked bar plot**, which simply stacks the count of observations in each `homeownership` type, coloring by `application_type`. We can see that most of the loan applicants live in mortgaged homes, but it's hard to say if a joint versus individual applicant is more or less likely to rent, own, or have a mortgage. 

```{r stacked, fig.margin=TRUE, fig.asp = 0.8, out.width="100%"}
loans %>% 
  ggplot() +
  geom_bar(aes(x = homeownership, fill = application_type)) 
```

### Exercise (work solo or with neighbors): 

Refer to the documentation for `geom_bar()` to make two different versions of the stacked bar plot, each of which communicates these two categorical variables differently.

1. Make a **dodged bar plot**, which has two bars for each homeownership category, one next to each other (or, "dodged"). One bar is the count of applicants in that homeownership category that are individual applicants, and the other that are joint applicants. 

2. Make a **standardized bar plot** (also known as **filled bar plot**), which shows two bars stacked on top of each other, each indicating the proportion of loan applicants in each homeownership category that are joint (one color) versus individual (a second color). 

> What do you notice about each bar plot type? When might one version be helpful and another not?

### Answers:

- Here's a  **dodged bar plot**, which puts the "stacks" by applicant type next to each other. It's often easier to see the total quantity in each category this way.

```{r dodged, fig.margin=TRUE, fig.asp = 0.8, out.width="100%"}
loans %>% 
  ggplot() +
  geom_bar(aes(x = homeownership, fill = application_type),
           position = "dodge") 
```

- Here is a **standardized bar plot**. It's easiest to see the relationships _between_ the two categories here, but you can't learn about the total number of applications. 

```{r standardized, fig.margin=TRUE, fig.asp = 0.8, out.width="100%"}
loans %>% 
  ggplot() +
  geom_bar(aes(x = homeownership, fill = application_type),
           position = "fill") 
```

# Section 2: Summarizing numerical data in `R`

## Histograms

As we discussed in class, we can make a histogram from our _sample_ to learn about what the probability density function of our _population_ is likely to look like. For example, you might want to know if your variable follows a normal distribution or not.

A histogram plots the count (or proportion) of your data that fall into a set of user-specified bins.^[Note: Even if you're working with continuous data, any histogram function in `R` will bin up your continuous data into discrete bins, and then plot the proportion of your data in that bin.]

We'll use `ggplot` and the `geom_histogram` function to make a histogram of the interest rate associated with all the loans in our loan database.  

```{r hist1}
ggplot(data = loans) + 
  geom_histogram(aes(x = interest_rate)) 
```

The above plot showed us _counts_ in each bin, where the bins were left unspecified.^[`R` will remind you to change bin values if you leave them unspecified, since the default is rarely appropriate for your data.] The command `breaks = seq(5, 27.5, 2.5)` creates a vector called `breaks` that goes from 5 to 25 in intervals of 2.5. Generate this vector and use it within `geom_histogram()` to create new bin widths in your histogram. 

This new histogram describes our data more clearly. What do you see? Use terms from class (e.g., symmetric, skew, tails, etc.) to describe the distribution of the interest rate in this sample of loans. Is the interest rate approximately normally distributed?

```{r hist2}
ggplot(data = loans) +
  geom_histogram(aes(x = interest_rate)) +
  scale_x_continuous(breaks = seq(5, 27.5, 2.5))
```

Note: If you want to make a histogram showing _proportions_ instead of counts, you can use `aes(y=..density..)` inside `geom_histogram()`.

## Box plots: A nice way to look at quantiles

Box plots are a standard way for us to visualize quantiles of a variable. Recall, quantiles tell us how much of our data sit below a certain value (e.g., the first tercile or first 3-quantile tells us the value at which 1/3 of the data sit below.).

In their most standard form, box plots show a _box_ where the outer edges of the box indicate the 1st and 3rd quartiles of the data (i.e., 25th and 75th percentiles).^[Recall: The range from the 25th to 75th percentile is called the "inter-quartile range" or IQR.] A vertical line is shown through the box indicating the 2nd quartile (i.e., 50th percentile or median). Lines outside the box are called "whiskers" and indicate the median minus (or plus) 1.5 times the IQR. While this is the most standard boxplot, you can customize these cutoffs to any quantiles you'd like.

Here, we repeat the histogram above, showing the distribution of the `interest_rate` variable in the data. We then make a boxplot using the standard quantiles. Note that outliers beyond the median + 1.5$\times$IQR are shown as individual points.

```{r}
ggplot(data = loans) +
  geom_histogram(aes(x = interest_rate)) +
  scale_x_continuous(breaks = seq(5, 27.5, 2.5))

ggplot(data = loans) +
  geom_boxplot(aes(x = interest_rate))
```

What do you notice in the boxplot? Do you prefer communicating skew, tails, and symmetry with the histogram or the boxplot? Why?

# [Optional] Section 3: Law of Large Numbers

The Law of Large Numbers tells us that as a randomly drawn sample increases in size, the sample average $\bar x$ converges towards the true population mean $\mu$. Here, we are going to show that this is true through running a "simulation" in `R`. That is, we will specify the true population mean, generate some fake data that are randomly drawn, and see how $\bar x$ compares to $\mu$ for different population sizes. We are hoping that as our sample size $n$ grows, our sample mean gets closer and closer to the true $\mu$.

To do this follow the following steps: 

1. For each $n$ from 1 to 1,000, randomly draw a sample size of $n$ from the standard normal distribution, which we know has $\mu=0$ and $\sigma=1$.^[Hint: `rnorm(x)` is a function that randomly draws $x$ numbers from the normal distribution.]

2. For each of your 1,000 samples, compute the sample mean $\bar x_n$.

```{r}

```

3. Plot on a graph the sample mean ($y$-axis) against the sample size ($x$-axis). Use `graphically that the mean of the samples will approach the expected value of the mean and standard deviation of the population.

```{r}

```


