---
title: "Week 6 Lab"
author: "Tom Gibbens-Matsuyama"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

---
title: "EDS222 Week 6 Lab: Logistic Regression"
format: 
  html:
    echo: true
    eval: false
    code-tools: true
bibliography: references.bib
---

# The Color of Drinking Water

Is exposure to environmental hazards influenced by *class* or *race and ethnicity*? Switzer and Teodoro [@switzer2017] argued the either-or framing of that question is misguided, and actually the *interaction* between class and race/ethnicity is the important question for environmental justice. Today's lab will use logistic regression and interaction terms to investigate drinking water quality in the context of socio-economic status (SES), race, and ethnicity.

# Overview

1.  Data exploration
2.  Try (and fail) to use OLS
3.  Fit a logistic regression model using maximum likelihood
4.  Fit the full logistic regression model using `glm()`

# Data exploration

We will use the data from @switzer2017 for today's lab. Begin by downloading the CSV file available [here](https://drive.google.com/file/d/1_1vgFyUxWW7XNzNcVzd32UY9502TspXn/view?usp=drive_link). These data come from multiple sources.

## Water utility and violations data

-   Source: Safe Drinking Water Information System (SDWIS)

-   Time period: 2010-2013 (4 years)

-   Sample size: 12,972 utilities

-   Criteria: Local government-owned utilities serving populations of 10,000 or more

## Demographic data

-   Source: US Census Bureau's American Community Surveys (2010-2013)

-   Variables included:

    -   Percent Hispanic population

    -   Percent Black population

    -   Percent of population with high school education

    -   Percent of population with bachelor's degree

    -   Percent of population below poverty line

    -   Median household income

Load the data and begin exploring.

```{r}
#| label: setup

suppressMessages(library(tidyverse))
theme_set(theme_bw())

drinking_water <- read_csv("drinking_water.csv", show_col_types = FALSE)

```

## Questions

1.  What do you think each row represents?

    **Demographics and water safety in a given district in a given year**

2.  What columns do you think represent:

    1.  Drinking water health violations?

        **Health**

    2.  Percent Black and Hispanic population in the utility district?

        **Pctblack, pcthisp**

    3.  Median household income in the utility district?

        **medianincomehouse**

3.  One column includes a *count* of drinking water health violations. How would you create a new column with a binary variable representing whether there were any violations?

```{r}
# Vectorized if_else statement
drinking_water = drinking_water %>% 
  mutate(violation = if_else(health == 0, 0, 1))
```

4.  Create a scatter plot of violations against race (percent Black population), ethnicity (percent Hispanic population), and SES (median household income). What visualization issues do we get with a scatter plot? How could you address that?\

    **The points are overplotted, i.e., too many are overlapping to see the trend. We can summarize within bins to make the pattern pop.**

```{r}
drinking_water_binned <- drinking_water %>% 
  mutate(pcthisp = round(pcthisp * 5) / 5) %>% 
  group_by(pcthisp) %>% 
  summarize(violation = mean(violation))

# Make plots
ggplot(drinking_water, aes(pcthisp, violation)) +
  geom_point() +
  geom_point(data = drinking_water_binned, color = 'firebrick')
```

# Try (and fail) to use OLS

Fit the following OLS model.

$$
\text{violations} = \beta_0 + \beta_1\text{percentHispanic}
$$

```{r}
pcthisp_lm <- lm(violation ~ pcthisp, data = drinking_water)
summary(pcthisp_lm)

```

## Questions

1.  Plot the residuals. What pattern do you notice?

```{r}
# Make a plot of the residuals.
drinking_water_complete <- drop_na(drinking_water,
                                   pcthisp,
                                   violation)
drinking_water_complete %>% 
  mutate(residual = resid(pcthisp_lm)) %>% 
  ggplot(aes(pcthisp, residual)) + 
  geom_point() +
  geom_abline(intercept = 8.132e-02, slope = 3.711e-04)



```

2.  Plot the raw data and the predicted probabilities for `violations`. Are there any obvious problems?

```{r}
# Plot raw data and predicted probabilities
ggplot(drinking_water, aes(pcthisp, violation)) +
  geom_point() +
  geom_point(data = drinking_water_binned, color = 'firebrick') +
  geom_abline(slope = coef(pcthisp_lm)[2],
              intercept = coef(pcthisp_lm)[1],
              color = "cornflowerblue",
              linewidth = 1.5)
```

# Fit a logistic regression model using maximum likelihood

Recall that logistic regression uses *maximum likelihood*, not OLS, to estimate coefficients. Usually we will use functions from R packages to fit these models, but I want you to do it yourself once.

## Negative log likelihood

Estimating coefficients is an optimization problem: what combination yields the maximum likelihood? There are two things we can do to make our problem more tractable for optimization.

1.  Recall that the likelihood function involves a *product*. Multiplication is computationally costly (compared to addition) and multiplying small numbers is very error prone. We can avoid this problem by working with logarithms. The log of a product is the sum of the logs: $log(a \times b) = log(a) + log(b)$. Logarithms are monotonically increasing, which means if $a > b$ then $log(a) > log(b)$. This useful property means we can maximize the sum of the log likelihoods (which is quick and robust to errors) instead of the product of likelihoods (which is slow and error prone).
2.  Optimization algorithms typically find the *minimum* value. They're intended to look for valleys, not peaks. So instead of maximizing the log likelihood, we can minimize the negative log likelihood.

That seems confusing! Let's write the code and so we can see what's happening. Do the following:

1.  Write a likelihood function for the violations and percent Hispanic model. This should calculate the negative log likelihood of a set of coefficients, conditional on the data.
2.  Call an optimization function to find the maximum likelihood parameters.

It will help to keep the model formulation handy:

$$
\begin{align}
\text{violations} &\sim Bernoulli(p) \\
logit(p) &= \beta_0 + \beta_1 \text{percentHispanic}
\end{align}
$$

```{r}
# Inverse logit utility function
inv_logit <- function(x) exp(x) / (1 + exp(x))
  
# Likelihood of the coefficients, given the data
likelihood_fun <- function(coefficients, data) {
  # coefficients looks like: c(beta0 = ??, beta1 = ??)
  # Calculate logit(p) based on coefficients and predictor
  logit_p <- coefficients["beta0"] + coefficients["beta1"] * data$pcthisp

  # Invert the logit to get p
  p <- inv_logit(logit_p)

  # Use the PMF of the Bernoulli to get our log likelihoods
  loglik <- dbinom(data$violation, size = 1, prob = p, log = TRUE)

  # Sum the negative log likelihood
  negloglik <- -sum(loglik)

}

# Use an optimization function to get the maximum likelihood coefficients
drinking_water_complete <- drop_na(drinking_water, pcthisp, violation)
coef_optim <- optim(c(beta0 = 0, beta1 = 0), 
                    likelihood_fun, 
                    data = drinking_water_complete)

```

## Questions

1.  What were your maximum likelihood estimates for $\hat\beta_0$ and $\hat\beta_1$?

```{r}
# What are the maximum likelihood estimates for our coefficients?
# Hint: explore coef_optim
coef_optim$par
beta0_hat <- coef_optim$par[1]
beta1_hat <- coef_optim$par[2]
```

2.  What's the predicted probability of drinking water violations for communities with 0%, 50%, and 100% Hispanic population?\
    Plot the predicted probability across the whole range 0-100% Hispanic.

```{r}
logit_p <- beta0_hat + beta1_hat * c(0, 50, 100)
p <- inv_logit(logit_p)
p 

# Create and plot predictions
tibble(pcthisp = 0:100,
       logit_p = beta0_hat + beta1_hat * pcthisp,
       p = inv_logit(logit_p)) %>% 
  ggplot(aes(x = pcthisp, y = p)) +
  geom_line()
```

3.  How much does the probability of a drinking water violation change when percent Hispanic population increases from 10 to 20%, 45 to 55%, and 80 to 90%?

```{r}
logit_p1 <- beta0_hat + beta1_hat * c(10, 45 , 80)
p1 <- inv_logit(logit_p1)
p1

logit_p2 <- beta0_hat + beta1_hat * c(20, 55 , 90)
p2 <- inv_logit(logit_p2)
p2

p_diff <- p2 - p1
p_diff
```

4.  How would you interpret the coefficients? What do the slope and intercept mean in this context? Where is the relationship linear, and where is it non-linear?

    **A: Beta0 is the intercept when pcthisp = 0. Beta1 is the slope, which is the change in the probability with each percent increase in pcthisp. The relationship is not linear in general.**

5.  Create a "DEM" of the likelihood landscape for $\beta_0$ and $\beta_1$. Choose a range of $\beta_0$ and $\beta_1$ values around your best estimates, calculate the likelihood for each combination, and create a figure with $\beta_0$ on the x-axis, $\beta_1$ on the y-axis, and the likelihood as the fill. Add a point for $(\hat\beta_0, \hat\beta_1)$.\
    Bonus problem: add contours!

```{r}
likelihood_dem <- expand_grid(
  beta0 = seq(-3, -2, length.out = 20), # our beta0 is -2.42, needs to fit w/i range -3 & -2 
  beta1 = seq(0, 0.01, length.out = 20) # beta1 is 0.0043, needs to fit w/i range  0-0.01
) %>% 
  mutate(coefficients = mapply(function(b0, b1) c(beta0 = b0, beta1 = b1),
                               beta0, beta1,
                               SIMPLIFY = FALSE),
         negloglik = sapply(coefficients, 
                            likelihood_fun, 
                            data = drinking_water_complete),
         likelihood = exp(-negloglik))

ggplot(likelihood_dem, aes(beta0, beta1, fill = negloglik)) +
  geom_raster() +
  geom_point(x = -2.42, y = 0.00439, color = "red")


## IN THIS MODEL, THE INTERCEPT IS CHANGING THE LIKELIHOOD A LOT. BETA0 IS CHANGING THE LIKELIHOOD. FOR BETA1, BIG CHANGES DONT REALLY CHANGE THE LIKELIHOOD. THE UNCERTAINITY FOR BETA0 IS VERY LOW, SO WE GOTTA REALLY NARROW CI. WITH BETA, CI GONNA BE WIDER. 
```

# Fit the full logistic regression model using `glm()`

Normally we won't need to write our own likelihood functions and use optimization to find our maximum likelihood coefficients. The `glm()` function in the built-in `stats` package can fit all kinds of generalized linear models, which includes logistic regression.

Here's how to fit the same model from the previous section. Notice the formula and data arguments look very similar to what we'd use for `lm()`. But now we have to specify the response variable's "family" (i.e., the type of random variable) and the link function we want to use (logit, in our case).

```{r}
pcthisp_glm <- glm(violation ~ pcthisp, 
                   family = binomial(link = "logit"),
                   data = drinking_water)
summary(pcthisp_glm)

```

## Questions

1.  How would you fit a model that includes an interaction term between ethnicity and SES?

```{r}
# SES = medianincomehouse
# ethnicity = pcthisp

interaction_glm <- glm(violation ~ pcthisp + medianincomehouse + pcthisp:medianincomehouse,
                       family = binomial(link = "logit"),
                       data = drinking_water)
summary(interaction_glm)

```

2.  Create a figure similar to Fig. 1 in @switzer2017. Put percent Hispanic population on the x-axis, median household income on the y-axis, and make the fill the probability of a water quality violation.

```{r}
predictions <- expand_grid(
  pcthisp = 0:100,
  medianincomehouse = seq(20000,100000, length.out = 100)
) %>% 
  mutate(violations = predict(interaction_glm, 
                              newdata = ., ####### this . means the data to left (piped in data) ########
                              type = "response"))

# Create plot
ggplot(predictions, aes(pcthisp, medianincomehouse, fill = violations)) +
  geom_raster() +
  scale_fill_distiller(palette = "Reds", direction = 1)
```

3.  Interpret the predicted surface. How does SES influence the relationship between ethnicity and exposure to environmental hazards? What is the "slope" of the probability of a violation w.r.t. percent Hispanic population at low, medium, and high median household income levels?\
